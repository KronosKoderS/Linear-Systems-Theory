{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Outline:\n",
    "1. [Vector Spaces](#Vector-Spaces)\n",
    "2. [Linear Dependance & Independence](#Linear-dependence-&-independence)\n",
    "3. [Change of Basis](#Change-of-Basis)\n",
    "4. [Linear Transformation between Vector Spaces](#Linear-Transformation-between-Vector-Spaces)\n",
    "5. [Nullspace and Range of a Linear Transformation](#Nullspace-and-Range-of-a-Linear-Transformation)\n",
    "6. [Linear Transformation and Matrices: Relationships](#Linear-Transformation-and-Matrices:-Relationships)\n",
    "7. [Application to Linear Systems: Geometric Interpretation](#Application-to-Linear-Systems:-Geometric-Interpretation)\n",
    "8. [Representation of an Operator in different basis](#Representation-of-an-Operator-in-different-basis)\n",
    "9. [Eigenvalue and Eigenvectors](#Eigenvalue-and-Eigenvectors)\n",
    "10. [Diagonal form of an operator](#Diagonal-form-of-an-operator)\n",
    "11. [Jordan form of a linear operator](#Jordan-form-of-a-linear-operator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sympy import init_printing, pprint\n",
    "\n",
    "init_printing(use_latex='mathjax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vector Spaces\n",
    "\n",
    "**Definition:** A non-empty space $E$ is called a $\\underline{\\text{Vector Space (vs)}}$ on a field $ \\mathbb{K}$ if between its elements ($\\underline{\\text{Vectors}}$), the following $\\underline{\\text{Compositional Laws}}$ are true:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. (Inner) (+) → sum (+): $ E \\times E \\rightarrow E$\n",
    "\n",
    "$ (\\underline{u},\\underline{v}) \\rightarrow \\underline{w} = \\underline{u} + \\underline{v}$\n",
    "\n",
    "with the following properties:\n",
    "\n",
    "1. Commutative: \n",
    "        \n",
    "    $ \\underline{u} + \\underline{v} = \\underline{v} + \\underline{u}, \\quad \\forall \\underline{u}, \\underline{v} \\in E$\n",
    "    \n",
    "2. Associative: \n",
    "\n",
    "    $ \\underline{u} + \\underline{v} + \\underline{w} = \\underline{u} + (\\underline{v} + \\underline{w}), \\quad \\forall \\underline{u},\\underline{v},\\underline{w} \\in E$\n",
    "    \n",
    "3. Neutral Element $\\underline{0}$ s.t. \n",
    "\n",
    "    $\\underline{u} + \\underline{0} = \\underline{0} + \\underline{u} = \\underline{u}, \\quad \\forall \\underline{u} \\in E$ \n",
    "    \n",
    "4. Inverse Element $(-\\underline{u})$ s.t. \n",
    "\n",
    "    $\\underline{u} + -\\underline{u} = -\\underline{u} + \\underline{u} = \\underline{0}, \\quad \\forall \\underline{u} \\in E$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2. (External on the field $\\mathbb{K}$): $\\mathbb{K} \\times E \\rightarrow E$\n",
    "\n",
    "$(\\lambda, \\underline{u}) \\rightarrow \\underline{w} = \\lambda\\underline{u}$\n",
    "\n",
    "with the following properties:\n",
    "\n",
    "5. Distributive w.r.t. the sum:\n",
    "\n",
    "    $\\lambda(\\underline{u} + \\underline{v}) = \\lambda\\underline{u} + \\lambda\\underline{v}, \\quad \\forall \\lambda \\in \\mathbb{K}, \\quad \\forall \\underline{u},\\underline{v} \\in E$\n",
    "    \n",
    "6. Distributive w.r.t. the sum in $\\mathbb{K}$:\n",
    "\n",
    "    $(\\lambda + \\mu)\\underline{v} = \\lambda\\underline{v} + \\mu\\underline{v}$\n",
    "    \n",
    "7. Associative\n",
    "\n",
    "    $\\lambda (\\mu \\underline{v}) = (\\lambda \\mu) \\underline{v}, \\quad \\forall \\lambda,\\mu \\in \\mathbb{K}, \\quad \\forall \\underline{v} \\in E$\n",
    "    \n",
    "8. Neutral element w.r.t. field $\\mathbb{K}$\n",
    "\n",
    "    $1 \\cdot \\underline{u} = \\underline{u} \\cdot 1 = \\underline{u}, \\quad \\forall \\underline{u} \\in E$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note:** $E$ has an algebraic structure of \"Albelian Group\"\n",
    "\n",
    "**Note:** $\\mathbb{K}$ can be real $\\mathbb{R}$ or complex $\\mathbb{C}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example A\n",
    "\n",
    "---\n",
    "$\\mathbb{R}^n = \n",
    "\\begin{equation}\n",
    "\\underbrace{\n",
    "\\mathbb{R} \\times \\mathbb{R} \\times \\dots \\times \\mathbb{R}\n",
    "}_{n-times} \n",
    "\\end{equation}\n",
    "$\n",
    "is the set of all $n$-ple of real numbers.  $(x_1, \\dots, x_n) \\in \\mathbb{R}^n \\Rightarrow $ it is a Vector Space $\\rightarrow$ indeed:\n",
    "\n",
    "$(x_1, \\dots, x_n) + (y_1, \\dots, y_n) = (x_1 + y_1, \\dots, x_n + y_n)$ with $(0, \\dots, 0)$ as netral element and $(-x_1, \\dots, -x_m)$ as inverse element.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example B\n",
    "\n",
    "---\n",
    "\n",
    "Consider the set $C(a, b)$ of all functions that are continuous & real in $(a, b) \\in \\mathbb{R}$.  Such set is a _vector space_\n",
    "\n",
    "$C(a, b) \\times C(a, b) \\rightarrow C(a, b)$\n",
    "\n",
    "$\\big(f(x), g(x)\\big) \\rightarrow h(x) = f(x) + g(x)$\n",
    "\n",
    "with $0(x) = 0$ in $(a, b)$ is the neutral function and $-f(x)$ s.t. $f(x) + (-f(x)) = 0(x)$ is the inverse fun.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear dependence & independence\n",
    "\n",
    "**Definition:** Let $\\lbrace \\underline{v}_1, \\dots, \\underline{v}_r \\rbrace$ be a set of r-vectors of $\\mathbb{E}$.  The vector $\\lambda_1\\underline{v}_1 + \\dots + \\lambda_r\\underline{v}_r$ is called the $\\underline{\\text{Linear Combination}}$ of the vectors on $\\mathbb{K}$.  \n",
    "\n",
    "**Definition:** $r$ vectors of $\\mathbb{E} \\lbrace \\underline{v}_1, \\dots, \\underline{v}_r \\rbrace$ are said to be $\\underline{\\text{Linearly Dependent (LD)}}$ if $\\exists \\, \\lambda_1, \\dots, \\lambda_r$ in $\\mathbb{K}$ not **all** zero s.t.: $\\lambda_1 \\underline{v}_1 + \\dots + \\lambda_r \\underline{v}_r = \\underline{0}$\n",
    "\n",
    "**Definition:** If $\\lambda_1 = \\dotsb \\lambda_r = 0 \\Rightarrow \\lbrace \\underline{v}_1, \\dots, \\underline{v}_2 \\rbrace$ are $\\underline{\\text{Linearly Independent (LI)}}$.\n",
    "\n",
    "**Definition:** We call the $\\underline{\\text{Basis}}$ of a vector space $\\mathbb{E}$ to be any LI systems of vectors capable of generating the all space by linear combination:  $\\mathbb{B} = \\lbrace \\underline{e}_1, \\dots, \\underline{e}_n \\rbrace \\Rightarrow \\underline{v} = v_1\\underline{e}_1 + \\dots + v_n\\underline{e}_n, \\quad \\forall \\underline{v} \\in \\mathbb{E}$\n",
    "\n",
    "$v_1, \\dots v_n$ are the components of $\\underline{v}$ w.r.t. the basis $\\mathbb{B}$.  $n$ is the $\\underline{\\text{Dimension}}$ of the vector space $\\mathbb{E}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Theorem:*** Let $\\mathbb{E}_n$ be a $vs^1$ of dimension $r$.  The vectors $\\lbrace \\underline{v}_1, ..., \\underline{v}_r \\rbrace$ are LI iff the rank of the following matrix is $r$:\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "v_1^1 & \\dots & v_r^1 \\\\\n",
    "\\vdots & \\ddots & \\dots \\\\\n",
    "v_1^n & \\dots & v_r^n \\\\\n",
    "\\end{vmatrix}\\rightarrow$ Matrix formed with the components of the vector $\\underline{v}_i\\,, i = 1, \\dots, r$ with respect to any basis $\\mathbb{B} = \\lbrace \\underline{e}_1, \\dots, \\underline{e}_n \\rbrace$\n",
    "\n",
    "$\n",
    "\\underline{v}_i = \\displaystyle\\sum_{j=1}^n v_i^j \\thinspace \\underline{e}_j, \\quad i = 1, \\dots, r\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Change of Basis\n",
    "\n",
    "Consider $\\mathbb{E}_n$ to be a vector space and let $\\lbrace \\underline{e}_1, \\dotsb, \\underline{e_n}\\rbrace = B \\notin \\lbrace \\underline{e}_{1'}, \\dotsb, \\underline{e}_{n'} \\rbrace = {B'}$ be two basis.  By definition, every vector of ${B'}$ can be expressed as a linear combination of $B$, i.e.\n",
    "\n",
    "$\\displaystyle\\underline{e}_{i'} = \\sum_{r=1}^n A_i^r, \\underline{e}_r, \\quad i' = 1, \\dots, n$ \n",
    "\n",
    "Inversely we have:\n",
    "\n",
    "$\\displaystyle\\underline{e}_s = \\sum_{s=1}^n A_s^{i'} \\underline{e}_{i'}, \\quad s = 1, \\dots, n$ (From ${B'} \\rightarrow B$)\n",
    "\n",
    "Substituting we have:\n",
    "\n",
    "$\\displaystyle\\underline{e}_s = \\sum_{s=1}^n \\sum_{r=1}^n A_{i'}^r A_s^{i'} \\underline{e}_r \\Rightarrow$ but since $B$ & ${B'}$ are LI we have:\n",
    "\n",
    "$\\displaystyle \\sum_{s=1}^n \\sum_{r=1}^r A_{i'}^r A_s^{i'} = \\delta_s^r = \n",
    "\\begin{cases}\n",
    "    1 & \\quad \\text{if } r = s\\\\\n",
    "    0 & \\quad \\text{if } r \\neq s\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The matrices $\\lbrace A_s^{i'} \\rbrace$ and $\\lbrace A_{i'}^r \\rbrace$ are inverse to each other $\\rightarrow$ we derive the following laws for change of basis:\n",
    "\n",
    "$\\lbrace B' = B\\underline{\\underline{A}} \\Leftrightarrow B = B'\\underline{\\underline{A}}^{-1} \\rbrace \\text{& } \\underline{\\underline{A}}\\underline{\\underline{A}}^{-1} = \\underline{\\underline{I}}$\n",
    "\n",
    "It is easy to show that the components fo a vector $v=E_n$ change in a <u>Controvariant</u> fashion with changing the basis, i.e.:\n",
    "\n",
    "$\\underline{u} = v' \\underline{e}_1 + \\dots + v^n \\underline{e}_n = \\displaystyle\\sum_{i=1}^n v^i \\underline{e}_i = \\sum_{i'=1}^n v^{i'} \\underline{e}_{i'}, \\quad \\text{and } \\quad \\lbrace V' = A^{-1}V \\Leftrightarrow V = AV' \\rbrace \\Rightarrow$ Controvariant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Transformation between Vector Spaces\n",
    "\n",
    "**Definition:** Let $E$ and $F$ be two Vector Spaces on $\\mathbb{K}$.  A $\\underline{\\text{Linear Transformation}}$ of $E$ in $F: L: E \\rightarrow F$ is a map such that $\\forall \\underline{x}, \\underline{y} \\in E, \\text{& } \\forall \\lambda \\in \\mathbb{K}$\n",
    "\n",
    "1. $L(\\underline{x} + \\underline{y}) = L(\\underline{x}) + L(\\underline{y})$\n",
    "2. $L(\\lambda\\underline{x}) = \\lambda L(\\underline{x})$\n",
    "\n",
    "or equivalently, \n",
    "\n",
    "$L(\\lambda_1 \\underline{x} + \\lambda_2 \\underline{y} = \\lambda_1 L(\\underline{x} + \\lambda_2 L(\\underline{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example A\n",
    "\n",
    "---\n",
    "$L: \n",
    "\\begin{matrix}\n",
    "    C^1(0, 1) \\rightarrow C^0(0, 1) \\\\\n",
    "    f(x) \\rightarrow \\frac{\\mathrm d}{\\mathrm d x}f(x)\n",
    "\\end{matrix}\n",
    "$ is linear\n",
    "\n",
    "$\\frac{\\mathrm d}{\\mathrm d x} \\big(\\lambda_1 f(x) + \\lambda_2 g(x) \\big) = \\lambda_1 f'(x) + \\lambda_2 g'(x)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example B\n",
    "\n",
    "---\n",
    "\n",
    "$L: \\begin{matrix}\n",
    "    C^0(0,1) \\rightarrow C^0(0,1) \\\\\n",
    "    f(x) \\rightarrow \\displaystyle\\int_0^x f(x')dx'\n",
    "\\end{matrix}\n",
    "$ is linear.\n",
    "\n",
    "$\\displaystyle \\int_0^x \\big(\\lambda_1 f(x') + \\lambda_2 g(x')\\big) dx' = \\lambda_1 \\int_0^x f(x')dx' + \\lambda_2 \\int_0^x g(x') dx'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nullspace and Range of a Linear Transformation\n",
    "\n",
    "**Definition:**  Let $L: E_n \\rightarrow F_m$ be a linear map.  The $\\underline{\\text{nullspace}} \\text{ } N(L)$ (also called kernel) is the subspace of $E_n$ s.t. $N(L) = \\big\\lbrace \\underline{x} \\in E_n \\, | \\, L \\underline{x} = \\underline{0} \\big\\rbrace$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Definition:** Let $L: E_n \\rightarrow F_m$ be a linear map.  The $\\underline{\\text{Raupe}}$ space of $L$, ($R(L)$) is the subspace of $F_m$ s.t.\n",
    "\n",
    "$R(L) = \\big\\lbrace \\underline{y} \\in F_m \\, | \\, L \\underline{x} = \\underline{y} \\big\\rbrace$\n",
    "\n",
    "The dimension of $R(L)$ is called $\\underline{\\text{rank}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Theorem:***  If Let $L: E_n \\rightarrow F_m$ and $dim \\, E_n = n, \\, dim \\, F_m = m$ then, $dim \\, E_n = dim \\, N(L) + dim \\, R(L)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Theorem:*** Two spaces are isomorphic if they have the same dimension.  \n",
    "\n",
    "Isomorphism: Linear application \n",
    "$L:\n",
    "\\begin{matrix} \n",
    "    E \\rightarrow F \\\\\n",
    "    \\underline{x} \\rightarrow y = L \\underline{x}\n",
    "\\end{matrix}\n",
    "$ s.t.\n",
    "\n",
    "1. one-to-one:\n",
    "    \n",
    "    $L(\\underline{x}_1) \\neq L(\\underline{x}_2)$ if $\\underline{x}_1 \\neq \\underline{x}_2 \\quad \\forall \\underline{x}_1, \\underline{x}_2 \\in E_n$\n",
    "    \n",
    "2. Onto:\n",
    "\n",
    "    For any $\\underline{y} \\in F, \\exists\\, \\underline{x} \\in E$ s.t. $L(\\underline{x}) = \\underline{y}$\n",
    "    \n",
    "    Note that the \"onto\" implies that $L(\\underline{x})$ (Roupe) covers the all space $F$.  But then $dim \\, R(L) = dim\\, F = m = n \\Rightarrow dim\\, E_n = n = dim\\, N(L) + dim\\, R(L) \\Rightarrow dim\\, N(L) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# TODO: Add figures or python graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Transformation and Matrices: Relationships\n",
    "\n",
    "Let $E_n$ and $F_m$ be two vector spaces on $\\mathbb{K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Theorem:*** if $\\lbrace \\underline{e}_1, \\dots, \\underline{e}_n \\rbrace$ is a basis of $E_n$, the linear map $L: E_n \\rightarrow F_m$ is uniquiely determined by the $n$-transformed vectors of the bases $\\lbrace \\underline{f}, \\dots , \\underline{f}_m \\rbrace$.  The linear map $L$ is uniquely represented by a matrix $m \\times n$.  Conversely, any matrix $(m \\times n)$ represents a linear map $L: E_n \\rightarrow F_m$\n",
    "\n",
    "Set the following basis in $E_n \\lbrace \\underline{e}_1, \\dots, \\underline{e}_n \\rbrace$.  Any vector $\\underline{x}$ in $E_n$ can be written as: $\\displaystyle \\sum_{i=1}^n x_i \\underline{e}_i$.  The transformed under $L$ are the following: $L \\underline{x} = \\displaystyle \\sum_{i=1}^n x^i \\begin{equation}\\underbrace{L \\underline{e}_i}_{\\underline{\\mathcal{E}}_i}\\end{equation} = \\sum_{i=1}^n x^i \\underline{\\mathcal{E}}_i$\n",
    "\n",
    "$\\mathcal{E}_i = L \\underline{e}_i$ can be represented in the basis $\\big\\lbrace \\underline{f}_1, \\dots, \\underline{f}_m \\big\\rbrace$\n",
    "\n",
    "$\\mathcal{E}_i = \\displaystyle \\sum_j^m \\alpha_i^j\\, \\underline{f}_j, \\quad i = 1, \\dots, n \\quad \\quad \\lbrace x_i^j \\rbrace_{\n",
    "\\begin{matrix}\n",
    "    i\\, = 1,\\, \\dots\\,,\\, n \\\\\n",
    "    j\\, = 1,\\, \\dots\\,,\\, m\n",
    "\\end{matrix}\n",
    "}$\n",
    "is a $m \\times n$ matrix!\n",
    "\n",
    "The $\\lbrace x_i^j \\rbrace$ matrix uniqutely represents the transformation of L.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Application to Linear Systems: Geometric Interpretation\n",
    "\n",
    "$\n",
    "\\begin{cases}\n",
    "   \\begin{matrix}\n",
    "       a_1^1 x^1 + & \\dots & a_n^1 x^n = y^1\n",
    "   \\end{matrix} \\\\\n",
    "   \\begin{matrix}\n",
    "       a_1^m x_1 + & \\dots & a_m^n x^n = y^m\n",
    "   \\end{matrix}\n",
    "\\end{cases}\n",
    "\\Rightarrow \\quad\n",
    "\\overbrace{A}^{(m \\times n)} \\underbrace{\\underline{x}}_{(n \\times 1)} = \\underbrace{\\underline{y}}_{(m \\times 1)}$ is a linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem: Does the System Have a Solution?\n",
    "\n",
    "If $A$ represents a map $\\underline{x} \\rightarrow \\underline{y}$, solutions can exist if and only if $\\underline{y}$ is in the range of $L$ or $\\underline{y} \\in R(A)$.  Since the range of $A$ is represented by the columns of $A$, that implies that $\\underline{y}$ must be expressed as linear combinations of the column of $A$.  \n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    A\\underline{e}_1 & A \\underline{e}_2 & \\dots & A \\underline{e}_n \\\\\n",
    "    \\vdots           & \\vdots            & \\vdots& \\vdots            \n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\underline{x} = \\underline{y} \\Rightarrow x' (A \\underline{e}_1) + \\dots + x^n (A \\underline{e}_m) = \\underline{y}\n",
    "$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Homegenous Systems: $A \\underline{x} = \\underline{0} \\rightarrow$ Solutions of $m \\times n$ homegenous systems form a vector space $\\rightarrow$ Null space of the application.\n",
    "\n",
    "# TODO: Insert Figure here\n",
    "\n",
    "   \n",
    "$A \\underline{x} = \\underline{0}$ if $m = n \\notin \\mathbb{R}(A) = rnk(A) = n \\Rightarrow$\n",
    "\n",
    "$\\Rightarrow dim E_n = \\dim N(A) + \\dim \\mathbb{R}(A) \\Rightarrow n = \\dim N(A) + n$\n",
    "\n",
    "$\\Rightarrow \\dim N(A) = 0 \\Rightarrow $ only possible solution for $A \\underline{x} = \\underline{0}$ is $\\underline{x} = \\underline{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Solution for $A \\underline{x} = \\underline{y}$:\n",
    "\n",
    "The general solution is the sum of **any** solution for $A \\underline{x} = \\underline{y}$ plus the general solution for the homogeneous system $A \\underline{x} = \\underline{0}$\n",
    "\n",
    "Indeed: if $\\underline{x} = \\underline{x}_P + \\underline{x}_H$, we have:\n",
    "\n",
    "$A \\underline{x} = A \\underline{x}_P + A \\underline{x}_H = \\underline{y} + \\underline{0}$\n",
    "\n",
    "thus the solution can be expressed as:\n",
    "\n",
    "$\\underline{x} = \\underline{x}_P + \\underbrace{c_1 \\underline{x}_1 + \\dots + c_k \\underline{x}_k}_{\\text{Fundamental (LI) solutions of } N(A)} \\quad \\text{where } k = n - \\dim \\mathbb{R}(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representation of an Operator in different basis\n",
    "\n",
    "A linear transformation $L: E_n \\rightarrow E_n$ is also called an $\\underline{Operator}$. \n",
    "\n",
    "Let ${\\lbrace \\underline{e}_i \\rbrace}_{i = 1, \\dots, n}$ and ${\\lbrace \\underline{e}_i' \\rbrace}_{i' = 1, \\dots, n}$ two basises of $E_n$.  Let $C$ be the matrix $(n \\times n)$ representing the change of basis $B \\rightarrow B'$.  That is:\n",
    "\n",
    "$\\lbrace \\underline{e}_1', \\dots, \\underline{e}_n \\rbrace = \\lbrace \\underline{e}_1, \\dots, \\underline{e}_n \\rbrace C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $\\underline{\\underline{A}}$ be the matrix represetnting a linear operator $L$ in $B$.  Conversely, let $\\underline{\\underline{A}}'$ be the matrix representing the smae operator in $B'$.  The following relationship holds:\n",
    "\n",
    "$\n",
    "\\begin{cases} \n",
    "    X' = C^{-1}X \\\\ \n",
    "    X = CX' \n",
    "\\end{cases} \\text{,}\\quad \\text{if } Y = \\underline{\\underline{A}}X \\text{ it is also true that } \n",
    "\\begin{cases} \n",
    "    Y' = C^{-1}Y \\\\ \n",
    "    Y = CY' \n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus we have:\n",
    "\n",
    "$ Y = \\underline{\\underline{A}} X \\Rightarrow CY' = \\underline{\\underline{A}} CX' \\Rightarrow Y' = C^{-1} \\underline{\\underline{A}} C X' = \\underline{\\underline{A}}' X'$\n",
    "\n",
    "thus the law of transformation is the following:\n",
    "\n",
    "$\\big\\lbrace A' = C^{-1} A C \\Longleftrightarrow A = C A'C^{-1}\\big\\rbrace$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Definition**:  Two $(n \\times n)$ matrices $A, B$ s.t. $A = CBC^{-1}$ where $C$ is an $(n \\times n)$ invertible matrix, are said to be $\\underline{similar}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eigenvalue and Eigenvectors\n",
    "\n",
    "**Definition:** For a given linear map $A: E_n \\rightarrow E_n$ (operator), an element $\\lambda \\in \\mathbb{K}$ is called an $\\underline{eigenvalue}$ if $\\exists \\, {v} \\in E_n, \\,\\, \\underline{v} \\neq \\underline{0} \\,\\,$ s.t. $A \\underline{v} = \\lambda \\underline{v}$ where $\\underline{v}$ is called the $\\underline{eigenvector}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "***Theroem:***  Let $E_\\lambda$ be the set of all vectors $\\underline{u}$, s.t. $A \\underline{u}_i = \\lambda \\underline{u}_i$.  The set $E_\\lambda$ plus $\\underline{0}$ is a vector subspace of $E$.  $E_\\lambda$ is called the $\\underline{eigenspace}$ of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to find eigen-values (e-values):\n",
    "\n",
    "Set the basis $\\lbrace \\underline{e}_i \\rbrace_{i=1}^n$ for $E_n$.  $A$ is then represented by a matrix $A (n \\times n)$.  To find the evalues, solve for the following:\n",
    "\n",
    "$A \\underline{v} = \\lambda \\underline{v}$ or $(A - \\lambda I) \\underline{v} = \\underline{0} \\rightarrow \\text{ homogenous system of linear equations}.$\n",
    "\n",
    "The solution is non-trivial iff $\\det(A - \\lambda I) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The equation $\\det (A - \\lambda I) = 0$ is an equation of depre $n$ called the $\\underline{\\text{characteristic equation}}$ and the $\\det(A-\\lambda I)$ is the $\\underline{\\text{characteristic polynomial}}$ of $A$, sometimes indicated with $P_A(\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "***Theroem:*** Similar matrices $A' = C^{-1} A C$ have the same characteristic Polynomial, i.e.:\n",
    "\n",
    "$P_{A'}(\\lambda) = P_A(\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Finding Eigenvalue and Eigenvectors using python:\n",
    "\n",
    "Using the numpy linear algebra library, the eigen values and eigen vectors can be determined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigen values are: 16.116843969807043, -1.1168439698070427, -1.3036777264747022e-15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "v, k = np.linalg.eig(A)\n",
    "\n",
    "print(\"The eigen values are: {v[0]}, {v[1]}, {v[2]}\".format(v=v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}-0.231970687246286 & -0.785830238742067 & 0.408248290463864\\\\-0.525322093301234 & -0.0867513392566283 & -0.816496580927726\\\\-0.818673499356181 & 0.61232756022881 & 0.408248290463863\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "⎡-0.231970687246286  -0.785830238742067   0.408248290463864 ⎤\n",
       "⎢                                                           ⎥\n",
       "⎢-0.525322093301234  -0.0867513392566283  -0.816496580927726⎥\n",
       "⎢                                                           ⎥\n",
       "⎣-0.818673499356181   0.61232756022881    0.408248290463863 ⎦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sympy import Matrix\n",
    "K = Matrix(k)\n",
    "display(K)  # use print or pprint in iPython console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Diagonal form of an operator\n",
    "\n",
    "**Question:**  Is it possible to choose a basis in $E_n$ s.t. $A: E_n \\rightarrow E_n$ is represented by the simplest matrix?\n",
    "\n",
    "**Definition:**  A operator $A$ is aid to be $\\underline{diagonizable}$ if $\\exists$ a basis of $E_n$ s.t. the matrix $A \\, (n \\times n)$ is diagonal.\n",
    "\n",
    "***Thereom:***  $A$ is diagonizable iff it admits $n$ linearly indpendent e-vectors, i.e. there exists a basis $E_n$ formed by e-vectors.\n",
    "\n",
    "**Definition:**  We call $\\underline{\\text{Geometric Multiplicity}} \\text{ (GM)}$ of e-value $\\lambda$ for $A$, the dimension of $E(\\lambda) = \\lbrace \\underline{x} \\in E | A \\underline{x} = \\lambda\\underline{x} \\rbrace$  Since $A \\underline{x} = \\lambda \\underline{x} \\Rightarrow GM = \\dim N(A - \\lambda I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Definition:**  We call $\\underline{\\text{Algebraic Multiplicity}} \\text{ (AM)}$ of e-value $\\lambda$ of $A$ the multiplicity of $\\lambda$ a sroot of the characteristic equation $\\det (A - \\lambda I) = 0$\n",
    "\n",
    "***Theroem:*** Let $A$ be an operator $A: E_n \\rightarrow E_n$, and let $\\lambda_1$ be an e-value.  Then:\n",
    "\n",
    "$\\begin{equation}AM(\\lambda_1) \\leq AM(\\lambda_1)\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "***Theroem:*** Let $A$ be an operator in $E_n$.  $A$ is $\\underline{diagonizable}$ iff, for any evalue of $A \\, \\lambda_i$, then:\n",
    "\n",
    "$GM(\\lambda_i) = AM(\\lambda_i) \\quad \\forall \\lambda_i$ s.t. $A \\underline{x} = \\lambda_i \\underline{x}$\n",
    "\n",
    "If $A$ is diagonal then $\\exists$ a basis of e-vectors such that $A$ **is similar** to a diagonal matrix:\n",
    "\n",
    "$\\begin{cases}\n",
    "    D = C^{-1} A C && \\underline{x} = \\mathbb{R}\\underline{z} \\\\\n",
    "    A = C D C\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Jordan form of a linear operator\n",
    "\n",
    "**Definition:**  We vall a $\\underline{\\text{Jordan matrix}}$ of order $n$, a matrix with the structure:\n",
    "\n",
    "$J_n = \n",
    "\\begin{bmatrix}\n",
    "    \\lambda  && \\dots  && 0 \\\\\n",
    "    0        && \\ddots && 0 \\\\\n",
    "    0       && \\dots   && \\lambda\n",
    "\\end{bmatrix}\n",
    "\\quad$  Where $J_n$ is a $n \\times n$ matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Theroem:***  Let $A$ be a linear operator in $E_n$ an $\\displaystyle P_A(\\lambda) = \\prod_{i=1}^z(\\lambda - \\lambda_i)^{z_i}$.  Then $A$ is similar to a matrix comprising Jordan blocks.  I.e. there exists a basis of vectors of $E_n$ (called generalize e-vectors) represented by a matrix $C$, such that the operator $A$ is similar to the following:\n",
    "\n",
    "$\\displaystyle\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "    \\begin{matrix} \\lambda_1 && \\dots && 0 \\\\ 0 && \\ddots && 0 \\\\ 0 && \\dots && \\lambda_1 \\end{matrix} && \\dots && 0\\\\\n",
    "    0 && \\ddots && 0 \\\\\n",
    "    0 && 0 && \\begin{matrix} \\lambda_z && \\dots && 0 \\\\ 0 && \\ddots && 0 \\\\ 0 && \\dots && \\lambda_z \\end{matrix} \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The similarity condition is expressed as:\n",
    "\n",
    "$J = C^{-1} A C \\Longleftrightarrow A = CJC^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theorem: (Cayley - Hamilton)\n",
    "\n",
    "**Definition:**  For a given polynomial $P(t) = a_0 t^n + a_1 t^{n-1} + \\dots + a_{n-1}t + a_n$ and an operator $A$ in $E_n$, we define the $\\underline{\\text{polynomial of operator}} \\, p(A)$, the following operator:\n",
    "\n",
    "$p(A) = a_0 A^{n} + a_1 A^{n-1} + \\dots + a_{n-1} A + a_n$\n",
    "\n",
    "Consider the operator $A$ represented by matrix $\\underline{\\underline{A}}$ in a specified basis $\\displaystyle \\lbrace \\underline{e}_i \\rbrace_{i=1}^n$.  Then the following is true:\n",
    "\n",
    "$P(\\underline{\\underline{A}}) = 0 \\text{ where } P(\\underline{\\underline{A}}) = \\det (\\underline{\\underline{A}} - \\lambda \\underline{\\underline{I}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Euclidean Vector Space\n",
    "\n",
    "Let $E$ be a vector space on $\\mathbb{R}$.  \n",
    "\n",
    "**Definition:**  We define the scalar product or inner product of $E$ as a bilinear transformation:  $g: E \\times E \\rightarrow \\mathbb{R}$ s.t. the following properties are true:\n",
    "\n",
    "1. $(\\underline{u}, \\underline{v} = (\\underline{v}, \\underline{u}), \\quad \\forall \\underline{u}, \\underline{v} \\in E$ (Commulative)\n",
    "2. $(\\alpha \\underline{u}, \\underline{v}) = (\\underline{u}, \\alpha \\underline{v}), \\quad \\forall \\underline{u}, \\underline{v} \\in E, \\quad \\forall \\alpha \\in \\mathbb{R}$\n",
    "3. $(\\underline{u}, \\underline{v} + \\underline{w}) = (\\underline{u}, \\underline{v}) + (\\underline{u}, \\underline{w}), \\quad \\forall \\underline{u}, \\underline{v}, \\underline{w} \\in E$\n",
    "4. $(\\underline{u}, \\underline{u}) \\geq 0, \\quad\\forall \\underline{u} \\in E$ and if $(\\underline{u}, \\underline{u}) = 0 \\Rightarrow \\underline{u} = \\underline{0}$\n",
    "\n",
    "Basically $ g(\\underline{u}, \\underline{v}) = \\underline{u} \\cdot \\underline{v}$ is a bilinear form on $E \\times E$ that is symmectical and positive definite.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Definition:**  A vector space $E$ is said to be $\\underline{Euclidean}$ if a scalar/inner product is defined on it.\n",
    "\n",
    "**Definition:**  Two vectors in $E$, $\\underline{u}, \\underline{v}$ are said to be orthogonal iff $(\\underline{u}, \\underline{v}) = \\underline{u} \\cdot \\underline{v} = 0$\n",
    "\n",
    "**Definition:**  We define $\\underline{norm}$ of a vector: $\\underline{u} \\in E$ the following $||\\underline{u}|| = \\sqrt{(\\underline{u}, \\underline{v})} = \\sqrt{\\underline{u} \\cdot \\underline{v}}$\n",
    "\n",
    "**Definition:**  A set of vectors $\\lbrace \\underline{e}_i \\rbrace_{i=1}^n$ is said to be orthonormal iff:\n",
    "\n",
    "$(\\underline{e}_i, \\underline{e}_k) = \\delta_{ik} \\begin{cases} 1, && \\text{if } i=k\\\\0, && \\text{if } i \\neq k\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adjoint Operators\n",
    "\n",
    "**Note:** A vector space on $C$ is said to be a Hilbert space if there is a inner product $g: E \\times E \\rightarrow C$ that satisfies the following properties:\n",
    "\n",
    "1. $(\\underline{u}, \\underline{v}) = (\\overline{\\underline{u}, \\underline{v}}) \\quad \\forall \\underline{u}, \\underline{v} \\in E$\n",
    "2. $(\\lambda \\underline{u} + \\mu \\underline{v}, \\underline{w}) = \\lambda (\\underline{u}, \\underline{w}) + \\mu (\\underline{v}, \\underline{w}) \\quad \\forall \\underline{u}, \\underline{v} \\in E, \\quad \\forall \\lambda, \\mu \\in C$\n",
    "3. $(\\underline{u}, \\underline{u}) \\geq 0 \\text{ and } (\\underline{u}, \\underline{u} = 0 \\Longleftrightarrow \\underline{u} = \\underline{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Consider now a Hilbert (Euclidean) space equipped with inner product. \n",
    "\n",
    "**Definition:**  We call $A^*$ adjoint operator of $A$, an operator that satisfies the following property:\n",
    "\n",
    "$(A \\underline{x}, \\underline{y}) = (\\underline{x}, A^*\\underline{y}), \\quad \\forall \\underline{x}, \\underline{y} \\in E$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An important class of operators are the $\\underline{self-adjoint}$ operators, i.e. operators like $A = A^*$:\n",
    "\n",
    "$(A\\underline{x}, \\underline{y}) = (\\underline{x}, A \\underline{y})$\n",
    "\n",
    "Note that if the space $E$ is Euclidean, then $A^* = A^T$ and $(A\\underline{x},\\underline{y}) = (\\underline{x}, A^T\\underline{y})$\n",
    "\n",
    "Self-adjoint operators are therefore $\\underline{Symmetric}$ $A=A^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Spectral Theorem\n",
    "\n",
    "A symmetric operator $A=A^T$ is always diagonizable.  Its e-values are all **real** and the e-vectors are orthogonal, i.e. $\\exists$ matrix $C$ made of e-vectors $C = \\big[\\underline{v}_1, \\dots, \\underline{v}_n\\big]$ s.t. the operator $A$ is similar to a diagonal operator (can be represented by a diagonal matrix in the basis of e-vectors).  \n",
    "\n",
    "For $A\\underline{v} = \\lambda \\underline{v}$ we can consider a transformation $x = M\\underline{v}$ s.t.\n",
    "\n",
    "$AM^{-1}\\underline{z} = \\lambda M^{-1}\\underline{z} \\Rightarrow MAM^{-1}\\underline{z} = \\lambda MM^{-1}\\underline{z} \\Rightarrow D\\underline{z} = \\lambda \\underline{z}$\n",
    "\n",
    "OR\n",
    "\n",
    "$\\big\\lbrace MAM^{-1} = D \\Longleftrightarrow A = M^{-1}DM \\big\\rbrace \\rightarrow \\text{ similarity condition}$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
